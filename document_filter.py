import os
import zipfile
import logging
import tempfile
import re
from pathlib import Path
from typing import List, Optional
import hashlib
from text_cleaner import preprocess_parsed_text

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    import rarfile
    RAR_SUPPORT = True
except ImportError:
    logger.warning("rarfile –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. RAR –∞—Ä—Ö–∏–≤—ã –Ω–µ –±—É–¥—É—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å—Å—è.")
    RAR_SUPPORT = False

def normalize_filename(filename: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –∞–Ω–∞–ª–∏–∑–æ–º:
    - —É–¥–∞–ª—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    - –∑–∞–º–µ–Ω—è–µ—Ç _, - –Ω–∞ –ø—Ä–æ–±–µ–ª
    - —É–¥–∞–ª—è–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–µ–ª—ã
    - –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    
    Args:
        filename: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        
    Returns:
        str: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    """
    name = re.sub(r'\.\w+$', '', filename)  # —É–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    name = name.replace("_", " ").replace("-", " ")
    name = re.sub(r'\s+', ' ', name)  # –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã ‚Üí –æ–¥–∏–Ω
    return name.strip().lower()

def is_useful_document(filename: str) -> bool:
    """
    –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –ø—Ä–∞–≤–∏–ª–∞–º:
    
    üü© ‚úÖ –í–∫–ª—é—á–∞–µ–º, –µ—Å–ª–∏:
    - –∏–º—è —Ñ–∞–π–ª–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–µ–∑–Ω—ã–µ —Å–ª–æ–≤–∞ (–∏–∑ must_include)
    - –∏–º—è –∫–æ—Ä–æ—Ç–∫–æ–µ (–º–µ–Ω–µ–µ 25 —Å–∏–º–≤–æ–ª–æ–≤) –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –º—É—Å–æ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 123.pdf)
    
    üü• ‚ùå –ò—Å–∫–ª—é—á–∞–µ–º, –µ—Å–ª–∏:
    - –∏–º—è —Å–æ–¥–µ—Ä–∂–∏—Ç –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ (–∏–∑ must_exclude)
    - —ç—Ç–æ Excel-—Ñ–∞–π–ª (.xls/.xlsx)
    - –¥–ª–∏–Ω–Ω–æ–µ –∏–º—è (25+ —Å–∏–º–≤–æ–ª–æ–≤), –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
    
    Args:
        filename: –ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        
    Returns:
        bool: True –µ—Å–ª–∏ —Ñ–∞–π–ª –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    """
    ext = Path(filename).suffix.lower()
    if ext in [".xls", ".xlsx"]:
        logger.debug(f"‚ùå –§–∞–π–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω (Excel —Ñ–æ—Ä–º–∞—Ç): {filename}")
        return False  # ‚ùå Excel –∏—Å–∫–ª—é—á–∞–µ–º

    name = normalize_filename(filename)

    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –î–û–õ–ñ–ù–´ –±—ã—Ç—å –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–µ)
    must_include = [
        "—Ç–∑", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ", "–æ–ø–∏—Å–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞", "–æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–∫—É–ø–∫–∏",
        "–≤–µ–¥–æ–º–æ—Å—Ç—å –ø–æ—Å—Ç–∞–≤–∫–∏", "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è", "—Ä–∞–∑–º–µ—Ä—ã", "–≥–∞–±–∞—Ä–∏—Ç—ã", 
        "—Å–æ—Ä—Ç", "—Å–æ—Å—Ç–∞–≤ –ø—Ä–æ–¥—É–∫—Ü–∏–∏", "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏", "–ø–∞—Ä–∞–º–µ—Ç—Ä—ã", 
        "–≥–æ—Å—Ç", "—Ç—É", "—É—Å–ª–æ–≤–∏—è –ø–æ—Å—Ç–∞–≤–∫–∏", "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ç–æ–≤–∞—Ä—É",
        "–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞", "–∫–∞—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–∞", "–¥–µ–∫–ª–∞—Ä–∞—Ü–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è"
    ]

    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –î–û–õ–ñ–ù–´ –±—ã—Ç—å –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–µ)
    must_exclude = [
        "–∫–æ–Ω—Ç—Ä–∞–∫—Ç", "–¥–æ–≥–æ–≤–æ—Ä", "–ø—Ä–æ–µ–∫—Ç –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞", "–ø—Ä–æ–µ–∫—Ç –¥–æ–≥–æ–≤–æ—Ä–∞",
        "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∑–∞—è–≤–∫–µ", "—Å–æ—Å—Ç–∞–≤ –∑–∞—è–≤–∫–∏", "–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏",
        "–∑–∞—è–≤–∫–∞", "–∑–∞—è–≤–ª–µ–Ω–∏–µ", "–Ω–º—Ü–∫", "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ", "—Ä–∞—Å—á–µ—Ç", 
        "—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ", "–≥–∞—Ä–∞–Ω—Ç–∏—è", "–æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ", "–æ—Ü–µ–Ω–∫–∞", 
        "–º–µ—Ç–æ–¥–∏–∫–∞", "–±–∞–ª–ª—ã", "–∫–æ–Ω—Ç—Ä–æ–ª—å", "–ª–∏—Å—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è", 
        "—Ñ–æ—Ä–º–∞", "—Ü–ø", "—Ä–µ—à–µ–Ω–∏–µ", "–ø—Ä–æ—Ç–æ–∫–æ–ª", "–∞–Ω–∫–µ—Ç–∞", 
        "—Å–æ–≥–ª–∞—Å–∏–µ", "–æ–±—Ä–∞–∑–µ—Ü –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è", "—Ä–µ–∫–≤–∏–∑–∏—Ç—ã", "—Ä–µ–≥–∏—Å—Ç—Ä",
        "—Å–≤–µ–¥–µ–Ω–∏—è –æ –∑–∞–∫–∞–∑—á–∏–∫–µ", "–¥–∞–Ω–Ω—ã–µ –∑–∞–∫–∞–∑—á–∏–∫–∞", "—Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ", 
        "—É—á–∞—Å—Ç–Ω–∏–∫ –∑–∞–∫—É–ø–∫–∏", "—É—á–∞—Å—Ç–Ω–∏–∫–∞", "–æ—Ç—á–µ—Ç"
    ]

    # –Ø–≤–Ω—ã–π –º—É—Å–æ—Ä
    if any(skip in name for skip in must_exclude):
        logger.debug(f"‚ùå –§–∞–π–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ —Å–ª–æ–≤–∞): {filename} (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{name}')")
        return False

    # –Ø–≤–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–π
    if any(key in name for key in must_include):
        logger.info(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é (–ø–æ–ª–µ–∑–Ω—ã–µ —Å–ª–æ–≤–∞): {filename} (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{name}')")
        return True

    # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–µ —á–∏—Å–ª–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Ç–∏–ø–∞ "123.pdf"
    if len(name) <= 25 and name.replace(" ", "").isalnum():
        logger.info(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é (–∫–æ—Ä–æ—Ç–∫–æ–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –∏–º—è): {filename} (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{name}')")
        return True

    # –í—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî –∏–≥–Ω–æ—Ä
    logger.debug(f"‚ùå –§–∞–π–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω (–¥–ª–∏–Ω–Ω–æ–µ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ –∏–º—è): {filename} (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{name}')")
    return False

def is_really_useful_by_text(text: str) -> bool:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç —Ñ–∞–π–ª –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.
    
    Args:
        text: –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
        
    Returns:
        bool: True –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    """
    text = text.lower()
    
    useful_markers = [
        "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞", "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏", "—Å—Ä–æ–∫ –ø–æ—Å—Ç–∞–≤–∫–∏", "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫",
        "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ", "–≥–æ—Å—Ç", "—Ç—É", "—É–ø–∞–∫–æ–≤–∫–∞", "—Å–æ—Ä—Ç", "—Ä–∞–∑–º–µ—Ä",
        "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏", "–ø–∞—Ä–∞–º–µ—Ç—Ä—ã", "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è", "–æ–ø–∏—Å–∞–Ω–∏–µ",
        "–∫–∞—á–µ—Å—Ç–≤–æ", "–º–∞—Ä–∫–∞", "—Ç–∏–ø", "–º–æ–¥–µ–ª—å", "–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è", "—Å–æ—Å—Ç–∞–≤"
    ]
    
    result = any(marker in text for marker in useful_markers)
    
    if result:
        logger.info(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É")
    else:
        logger.debug(f"‚ùå –§–∞–π–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É")
    
    return result

def extract_text_from_file(file_path: str) -> Optional[str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ.
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        
    Returns:
        Optional[str]: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        file_ext = Path(file_path).suffix.lower()
        
        if file_ext == '.txt':
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                return f.read()
        elif file_ext == '.pdf':
            # –î–ª—è PDF –∏—Å–ø–æ–ª—å–∑—É–µ–º PyPDF2 (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
            try:
                import PyPDF2
                with open(file_path, 'rb') as f:
                    pdf_reader = PyPDF2.PdfReader(f)
                    text = ""
                    for page in pdf_reader.pages:
                        text += page.extract_text() + "\n"
                    return text
            except ImportError:
                logger.warning("PyPDF2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. PDF —Ñ–∞–π–ª—ã –Ω–µ –±—É–¥—É—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.")
                return None
        elif file_ext == '.docx':
            # –î–ª—è DOCX –∏—Å–ø–æ–ª—å–∑—É–µ–º python-docx (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
            try:
                import docx
                doc = docx.Document(file_path)
                text = ""
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                return text
            except ImportError:
                logger.warning("python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. DOCX —Ñ–∞–π–ª—ã –Ω–µ –±—É–¥—É—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.")
                return None
        else:
            logger.debug(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {file_ext}")
            return None
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ {file_path}: {e}")
        return None

def extract_and_filter_archive(archive_path: str, dest_dir: str) -> List[str]:
    """
    –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ—Ç .zip –∏–ª–∏ .rar, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é.
    
    Args:
        archive_path: –ü—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É
        dest_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏
        
    Returns:
        List[str]: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º
    """
    filtered_files = []
    
    try:
        if archive_path.endswith(".zip"):
            archive = zipfile.ZipFile(archive_path)
            logger.info(f"–†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞—é ZIP –∞—Ä—Ö–∏–≤: {archive_path}")
        elif archive_path.endswith(".rar"):
            if not RAR_SUPPORT:
                logger.error("RAR –∞—Ä—Ö–∏–≤—ã –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ rarfile: pip install rarfile")
                return []
            archive = rarfile.RarFile(archive_path)
            logger.info(f"–†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞—é RAR –∞—Ä—Ö–∏–≤: {archive_path}")
        else:
            logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∞—Ä—Ö–∏–≤–∞: {archive_path}")
            return []
        
        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤
        archive.extractall(dest_dir)
        
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –≤ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for root, _, files in os.walk(dest_dir):
            for file in files:
                # –û—á–∏—â–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –æ—Ç —Å–∏–º–≤–æ–ª–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
                clean_filename = file.replace('\n', ' ').replace('\r', ' ').strip()
                clean_filename = re.sub(r'\s+', ' ', clean_filename)  # –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã ‚Üí –æ–¥–∏–Ω
                
                full_path = os.path.join(root, file)
                clean_full_path = os.path.join(root, clean_filename)
                
                # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ñ–∞–π–ª –µ—Å–ª–∏ –∏–º—è –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
                if file != clean_filename:
                    try:
                        os.rename(full_path, clean_full_path)
                        logger.info(f"–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω —Ñ–∞–π–ª: '{file}' ‚Üí '{clean_filename}'")
                        full_path = clean_full_path
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —Ñ–∞–π–ª '{file}': {e}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–µ–ª –ª–∏ —Ñ–∞–π–ª —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                if is_useful_document(clean_filename):
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Path().as_posix() –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –ø—É—Ç–∏
                    normalized_path = Path(full_path).as_posix()
                    filtered_files.append(normalized_path)
                    logger.info(f"–ù–∞–π–¥–µ–Ω –ø–æ–ª–µ–∑–Ω—ã–π —Ñ–∞–π–ª –≤ –∞—Ä—Ö–∏–≤–µ: {clean_filename}")
                else:
                    logger.debug(f"–§–∞–π–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –≤ –∞—Ä—Ö–∏–≤–µ: {clean_filename}")
        
        logger.info(f"–ò–∑ –∞—Ä—Ö–∏–≤–∞ {archive_path} –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_files)} —Ñ–∞–π–ª–æ–≤")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—Ä—Ö–∏–≤–∞ {archive_path}: {e}")
    
    return filtered_files

def filter_documents(paths: List[str], check_content: bool = False) -> List[str]:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –∏ –∞—Ä—Ö–∏–≤–∞–º, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.
    
    Args:
        paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –∏ –∞—Ä—Ö–∏–≤–∞–º
        check_content: –ü—Ä–æ–≤–µ—Ä—è—Ç—å –ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ (–≤—Ç–æ—Ä–∏—á–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è)
        
    Returns:
        List[str]: –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    """
    result = []
    temp_dirs_to_cleanup = []  # –°–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞–ø–æ–∫ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
    
    logger.info(f"–ù–∞—á–∏–Ω–∞—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é {len(paths)} —Ñ–∞–π–ª–æ–≤/–∞—Ä—Ö–∏–≤–æ–≤")
    
    for path in paths:
        path_obj = Path(path)
        
        if not path_obj.exists():
            logger.warning(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
            continue
            
        if path_obj.suffix.lower() in ['.zip', '.rar']:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤
            logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∞—Ä—Ö–∏–≤: {path}")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –≤ download_files/temp_cleaned/ –≤–º–µ—Å—Ç–æ —Å–∏—Å—Ç–µ–º–Ω–æ–π
            temp_dir = Path("download_files/temp_cleaned")
            temp_dir.mkdir(parents=True, exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é –ø–æ–¥–ø–∞–ø–∫—É –¥–ª—è —ç—Ç–æ–≥–æ –∞—Ä—Ö–∏–≤–∞
            import uuid
            unique_temp_dir = temp_dir / f"extract_{uuid.uuid4().hex[:8]}"
            unique_temp_dir.mkdir(exist_ok=True)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
            temp_dirs_to_cleanup.append(unique_temp_dir)
            
            extracted = extract_and_filter_archive(str(path), str(unique_temp_dir))
            result.extend(extracted)
                
        elif is_useful_document(path_obj.name):
            # –û–±—ã—á–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Path().as_posix() –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –ø—É—Ç–∏
            normalized_path = path_obj.as_posix()
            result.append(normalized_path)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
            if check_content:
                text = extract_text_from_file(normalized_path)
                if text and not is_really_useful_by_text(text):
                    logger.info(f"–§–∞–π–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É: {path}")
                    result.remove(normalized_path)
        else:
            logger.debug(f"–§–∞–π–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é: {path}")
    
    logger.info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ù–∞–π–¥–µ–Ω–æ {len(result)} –ø–æ–ª–µ–∑–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞–ø–æ–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –æ—á–∏—Å—Ç–∫–∏
    if hasattr(filter_documents, '_temp_dirs'):
        filter_documents._temp_dirs.extend(temp_dirs_to_cleanup)
    else:
        filter_documents._temp_dirs = temp_dirs_to_cleanup
    
    return result

def cleanup_temp_dirs():
    """
    –û—á–∏—â–∞–µ—Ç –≤—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –≤–æ –≤—Ä–µ–º—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞.
    """
    if hasattr(filter_documents, '_temp_dirs') and filter_documents._temp_dirs:
        import shutil
        for temp_dir in filter_documents._temp_dirs:
            try:
                if temp_dir.exists():
                    shutil.rmtree(temp_dir)
                    logger.debug(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–ø–∫–∞ –æ—á–∏—â–µ–Ω–∞: {temp_dir}")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É {temp_dir}: {e}")
        
        # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫
        filter_documents._temp_dirs = []
        logger.info("–í—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏ –æ—á–∏—â–µ–Ω—ã")

def filter_documents_with_content_check(paths: List[str]) -> List[str]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ.
    
    Args:
        paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –∏ –∞—Ä—Ö–∏–≤–∞–º
        
    Returns:
        List[str]: –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    """
    return filter_documents(paths, check_content=True)

def collect_clean_texts(file_paths: list, tender_number: str) -> dict:
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è, –æ—á–∏—Å—Ç–∫–∞, —Å–±–æ—Ä –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É {text, length, sources} –∏ –ª–æ–≥–∏—Ä—É–µ—Ç –≤—Å–µ —ç—Ç–∞–ø—ã.
    """
    import shutil
    from pathlib import Path
    import os
    import logging

    logger = logging.getLogger(__name__)
    logger.info(f"\n=== –°–¢–ê–†–¢ –û–ë–†–ê–ë–û–¢–ö–ò –¢–ï–ù–î–ï–†–ê {tender_number} ===")

    # 1. –°–æ–∑–¥–∞–µ–º temp_cleaned/{tender_number}
    temp_dir = Path(f"download_files/temp_cleaned/{tender_number}")
    if temp_dir.exists():
        shutil.rmtree(temp_dir)
    temp_dir.mkdir(parents=True, exist_ok=True)

    # 2. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    allowed_ext = {'.doc', '.docx', '.pdf', '.txt'}

    # 3. –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ –∏ —Å–±–æ—Ä –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
    all_files = []
    archive_files = set()
    for path in file_paths:
        p = Path(path)
        if p.suffix.lower() in ['.zip', '.rar']:
            logger.info(f"–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞: {p.name}")
            extract_dir = temp_dir / p.stem
            extract_dir.mkdir(exist_ok=True)
            try:
                if p.suffix.lower() == '.zip':
                    with zipfile.ZipFile(str(p), 'r') as zf:
                        zf.extractall(str(extract_dir))
                elif p.suffix.lower() == '.rar':
                    try:
                        import rarfile
                        with rarfile.RarFile(str(p)) as rf:
                            rf.extractall(str(extract_dir))
                    except Exception as e:
                        logger.warning(f"RAR –∞—Ä—Ö–∏–≤ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω: {p.name} ‚Äî {e}")
                        continue
                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ –∞—Ä—Ö–∏–≤–∞
                for root, _, files in os.walk(str(extract_dir)):
                    for f in files:
                        full_path = Path(root) / f
                        all_files.append(full_path)
                        archive_files.add(full_path.name)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–µ {p.name}: {e}")
        else:
            all_files.append(p)

    # 4. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∏–º–µ–Ω–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
    filtered = []
    ignored = []
    for f in all_files:
        ext = f.suffix.lower()
        if ext not in allowed_ext:
            logger.info(f"–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é: {f.name}")
            ignored.append(f)
            continue
        if not is_useful_document(f.name):
            logger.info(f"–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω –ø–æ —Ñ–∏–ª—å—Ç—Ä—É: {f.name}")
            ignored.append(f)
            continue
        filtered.append(f)

    # 5. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –∏–º–µ–Ω–∏ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
    seen_names = set()
    seen_hashes = set()
    unique_files = []
    hash_to_file = {}
    name_to_file = {}
    for f in filtered:
        norm_name = normalize_filename(f.name)
        try:
            with open(f, 'rb') as file:
                content = file.read()
                file_hash = hashlib.md5(content).hexdigest()
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {f}: {e}")
            continue
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –µ—Å–ª–∏ –¥—É–±–ª–∏—Ä—É–µ—Ç—Å—è, –±–µ—Ä–µ–º –∏–∑ –∞—Ä—Ö–∏–≤–∞
        if file_hash in seen_hashes:
            logger.info(f"–î—É–±–ª–∏–∫–∞—Ç –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É: {f.name}")
            continue
        if norm_name in seen_names:
            logger.info(f"–î—É–±–ª–∏–∫–∞—Ç –ø–æ –∏–º–µ–Ω–∏: {f.name}")
            continue
        seen_hashes.add(file_hash)
        seen_names.add(norm_name)
        hash_to_file[file_hash] = f
        name_to_file[norm_name] = f
        unique_files.append(f)

    logger.info(f"\n–ò—Ç–æ–≥–æ –ø–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(unique_files)} —Ñ–∞–π–ª–æ–≤")
    for f in unique_files:
        logger.info(f"–í–∫–ª—é—á–µ–Ω –≤ –∞–Ω–∞–ª–∏–∑: {f.name}")

    # 6. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ, –æ—á–∏—Å—Ç–∫–∞ –∏ —Å–±–æ—Ä —Ç–µ–∫—Å—Ç–∞
    from document_filter import extract_text_from_file
    sources = []
    texts = []
    cleaning_stats = {
        "underscore_lines_removed": 0,
        "long_numbers_removed": 0,
        "duplicates_removed": 0,
        "key_headers_found": 0
    }
    
    for f in unique_files:
        logger.info(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {f.name}")
        text = extract_text_from_file(str(f))
        if not text:
            logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω (–Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç): {f.name}")
            continue
        
        before = len(text)
        clean_result = preprocess_parsed_text(text)
        clean_text = clean_result["text"]
        file_stats = clean_result["stats"]
        
        # –°—É–º–º–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        for key in cleaning_stats:
            if key in file_stats:
                cleaning_stats[key] += file_stats[key]
        
        after = len(clean_text)
        logger.info(f"–¢–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω: {before} ‚Üí {after} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è —Ñ–∞–π–ª–∞
        logger.info(f"‚úÖ –§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {f.name}")
        logger.info(f"‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {before}")
        logger.info(f"‚Ä¢ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {after}")
        logger.info(f"‚Ä¢ –£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å '____': {file_stats.get('underscore_lines_removed', 0)}")
        logger.info(f"‚Ä¢ –£–¥–∞–ª–µ–Ω–æ –¥–ª–∏–Ω–Ω—ã—Ö —á–∏—Å–µ–ª: {file_stats.get('long_numbers_removed', 0)}")
        logger.info(f"‚Ä¢ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {file_stats.get('duplicates_removed', 0)}")
        logger.info(f"‚Ä¢ –í—ã–¥–µ–ª–µ–Ω–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: {file_stats.get('key_headers_found', 0)}")
        
        if after > 0:
            texts.append(clean_text)
            sources.append({
                "filename": f.name,
                "length": after,
                "original_length": before
            })
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –≤ –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç: {f.name}")
        else:
            logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω (–ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏): {f.name}")

    full_text = "\n\n".join(texts)
    logger.info(f"\n=== –ò—Ç–æ–≥–æ–≤—ã–π –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ {len(sources)} —Ñ–∞–π–ª–æ–≤ ===")
    logger.info(f"–ò—Å—Ç–æ—á–Ω–∏–∫–∏: {[s['filename'] for s in sources]}")

    if not sources:
        logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return {
            "success": False,
            "text": "",
            "length": 0,
            "sources": [],
            "log": cleaning_stats,
            "error": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
        }

    return {
        "success": True,
        "text": full_text,
        "length": len(full_text),
        "sources": sources,
        "log": cleaning_stats
    }

 